{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "\n",
    "import numpy as np\n",
    "import ast\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import scipy.optimize\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "    \"\"\" Read and convert the input to a list of dicts\"\"\"\n",
    "    for l in open(fname, encoding=\"utf-8\"):\n",
    "        yield ast.literal_eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt', encoding=\"utf-8\"):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = \"C:\\\\Users\\\\ramasarma\\\\Documents\\\\UCSD\\\\Fall 2020\\\\CSE 258\\\\Assignment1\\\\assignment1\\\\train.json\"\n",
    "dataset = list(readGz(\"C:\\\\Users\\\\ramasarma\\\\Documents\\\\UCSD\\\\Fall 2020\\\\CSE 258\\\\Assignment1\\\\assignment1\\\\train.json.gz\"))\n",
    "training_validation_boundary = 165000\n",
    "training_dataset = dataset[:training_validation_boundary]\n",
    "validation_dataset = dataset[training_validation_boundary:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_duplication(dataset, start, end):\n",
    "    assert(start <= len(dataset) and end <= len(dataset))\n",
    "    new_set = []\n",
    "    print(\"Start = {}, end = {}\".format(start, end))\n",
    "    for d in dataset[start:end]:\n",
    "        user, game = d['userID'], d['gameID']\n",
    "        gamesNotPlayed = []\n",
    "        for game in gameIDs:\n",
    "            if(game not in gamesPerUser[user]):\n",
    "                gamesNotPlayed.append(game)\n",
    "                \n",
    "        random.seed()\n",
    "        randomGame = random.choice(gamesNotPlayed)\n",
    "        new_data = {'hours': 0, 'gameID': str(randomGame),\\\n",
    "                'hours_transformed': 0, 'early_access': False,\\\n",
    "                'date': '', 'text': '', 'userID': str(userID)}\n",
    "        new_set.append(new_data)\n",
    "    return dataset + new_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation phase successfully completed...\n"
     ]
    }
   ],
   "source": [
    "usersPerGame = defaultdict(set) # list of userIDs per game\n",
    "gamesPerUser = defaultdict(set) # list of gameIDs per user\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerGame = defaultdict(list)\n",
    "gameIDs = [] # This contains the entire list of games\n",
    "hoursPerGame = defaultdict(list)\n",
    "hoursPerUser = defaultdict(list)\n",
    "\n",
    "usersPerGame_training = defaultdict(set) # list of userIDs per game\n",
    "gamesPerUser_training = defaultdict(set) # list of gameIDs per user\n",
    "reviewsPerUser_training = defaultdict(list)\n",
    "reviewsPerGame_training = defaultdict(list)\n",
    "gameIDs_training = [] # This contains the entire list of games\n",
    "hoursPerGame_training = defaultdict(list)\n",
    "hoursPerUser_training = defaultdict(list)\n",
    "\n",
    "usersPerGame_validation = defaultdict(set) # list of userIDs per game\n",
    "gamesPerUser_validation = defaultdict(set) # list of gameIDs per user\n",
    "reviewsPerUser_validation = defaultdict(list)\n",
    "reviewsPerGame_validation = defaultdict(list)\n",
    "gameIDs_validation = [] # This contains the entire list of games\n",
    "hoursPerGame_validation = defaultdict(list)\n",
    "hoursPerUser_validation = defaultdict(list)\n",
    "\n",
    "# Computing maps and lists for all samples\n",
    "for d in dataset:\n",
    "    userID, gameID, hours = d['userID'], d['gameID'], d['hours_transformed']\n",
    "    usersPerGame[gameID].add(userID)\n",
    "    gamesPerUser[userID].add(gameID)\n",
    "    reviewsPerUser[userID].append(d)\n",
    "    reviewsPerGame[gameID].append(d)\n",
    "    hoursPerGame[gameID].append((userID, hours))\n",
    "    hoursPerUser[userID].append((gameID, hours))\n",
    "    if gameID not in gameIDs:\n",
    "        gameIDs.append(gameID)\n",
    "        \n",
    "# Computing maps and lists for training set samples\n",
    "for d in training_dataset:\n",
    "    userID, gameID = d['userID'], d['gameID']\n",
    "    usersPerGame_training[gameID].add(userID)\n",
    "    gamesPerUser_training[userID].add(gameID) # list of gameIDs per user\n",
    "    reviewsPerUser_training[userID].append(d)\n",
    "    reviewsPerGame_training[gameID].append(d)\n",
    "    hoursPerGame_training[gameID].append((userID, hours))\n",
    "    hoursPerUser_training[userID].append((gameID, hours))\n",
    "    if gameID not in gameIDs_training:\n",
    "        gameIDs_training.append(gameID)\n",
    "        \n",
    "# Computing maps and lists for training set samples\n",
    "for d in validation_dataset:\n",
    "    userID, gameID = d['userID'], d['gameID']\n",
    "    usersPerGame_validation[gameID].add(userID)\n",
    "    gamesPerUser_validation[userID].add(gameID) # list of gameIDs per user\n",
    "    reviewsPerUser_validation[userID].append(d)\n",
    "    reviewsPerGame_validation[gameID].append(d)\n",
    "    hoursPerGame_validation[gameID].append((userID, hours))\n",
    "    hoursPerUser_validation[userID].append((gameID, hours))\n",
    "    if gameID not in gameIDs_training:\n",
    "        gameIDs_validation.append(gameID)\n",
    "\n",
    "print(\"Data preparation phase successfully completed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start = 0, end = 165000\n",
      "Start = 0, end = 10000\n",
      "Lengths of new datasets = 330000 and 20000\n"
     ]
    }
   ],
   "source": [
    "new_training_set = perform_duplication(training_dataset, 0, len(training_dataset))\n",
    "new_validation_set = perform_duplication(validation_dataset, 0, len(validation_dataset))\n",
    "print(\"Lengths of new datasets = {} and {}\".format(len(new_training_set), len(new_validation_set))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix for the given set of predictions and actual values\n",
    "def compute_confusion_matrix(Y_actual, Y_predict):\n",
    "    \"\"\" This function is used to compute the confusion matrix\"\"\"\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    assert(len(Y_actual) == len(Y_predict))\n",
    "    for i in range(len(Y_actual)):\n",
    "        if(Y_actual[i] == 1 and Y_predict[i] == 1):\n",
    "            TP += 1\n",
    "        elif(Y_actual[i] == 0 and Y_predict[i] == 1):\n",
    "            FP += 1\n",
    "        elif(Y_actual[i] == 0 and Y_predict[i] == 0):\n",
    "            TN += 1\n",
    "        elif(Y_actual[i] == 1 and Y_predict[i] == 0):\n",
    "            FN += 1\n",
    "    return (TP, TN, FP, FN)\n",
    "\n",
    "# Compute the ratios for computing the TP, TN, FP and FN\n",
    "def compute_rates(TP, TN, FP, FN):\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (FN + TP)\n",
    "    BER = 0.5 * (FPR + FNR)\n",
    "    return (TPR, TNR, FPR, FNR, BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(s1, s2):\n",
    "    numerator = len(s1.intersection(s2))\n",
    "    denominator = len(s1.union(s2))\n",
    "    return numerator/denominator\n",
    "\n",
    "# Helps compute the cosine similarity\n",
    "def cosine_similarity(s1, s2):\n",
    "    \"\"\" This only works for binary values in the sets\"\"\"\n",
    "    numerator = len(s1.intersection(s2))\n",
    "    denominator = math.sqrt(len(s1) * len(s2))\n",
    "    if(denominator == 0):\n",
    "        return 0\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pop(dataset, sim_th, pop_th):\n",
    "    idx, numerator = 0, 0\n",
    "    y_pred = []\n",
    "    y_act = []\n",
    "    for d in dataset:\n",
    "        u, g = d['userID'], d['gameID']\n",
    "        # Use hoursPerGame for popularity\n",
    "        # User based comparison for similarity\n",
    "        users = set(hoursPerGame_training[g])\n",
    "        max_sim = -1\n",
    "        for g2, _ in hoursPerUser_training[u]:\n",
    "            sim = jaccard(users, set(hoursPerGame_training[g2]))\n",
    "            max_sim = max(sim, max_sim)\n",
    "        # Compute the performance on validation set\n",
    "        if(max_sim > sim_th or len(hoursPerGame[g]) > pop_th):\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "        \n",
    "        if(idx < len(dataset)/2):\n",
    "            y_act.append(1)\n",
    "        else:\n",
    "            y_act.append(0)\n",
    "            \n",
    "        idx += 1\n",
    "    (TP, TN, FP, FN) = compute_confusion_matrix(y_act, y_pred)\n",
    "    (TPR, TNR, FPR, FNR, BER) = compute_rates(TP, TN, FP, FN)\n",
    "    acc = (TP + TN) / (FP + FN + TP + TN)\n",
    "    return (acc, BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and BER at sim_th, pop_th = 0.01, 20 are 0.5043 and 0.49570000000000003\n",
      "Accuracy and BER at sim_th, pop_th = 0.01, 40 are 0.5045 and 0.4955\n",
      "Accuracy and BER at sim_th, pop_th = 0.01, 60 are 0.5042 and 0.49579999999999996\n",
      "Accuracy and BER at sim_th, pop_th = 0.01, 80 are 0.50415 and 0.49584999999999996\n",
      "Accuracy and BER at sim_th, pop_th = 0.02, 20 are 0.54045 and 0.45955\n",
      "Accuracy and BER at sim_th, pop_th = 0.02, 40 are 0.59145 and 0.40854999999999997\n",
      "Accuracy and BER at sim_th, pop_th = 0.02, 60 are 0.5943 and 0.4057\n",
      "Accuracy and BER at sim_th, pop_th = 0.02, 80 are 0.5942 and 0.4058\n",
      "Accuracy and BER at sim_th, pop_th = 0.03, 20 are 0.56885 and 0.43115\n",
      "Accuracy and BER at sim_th, pop_th = 0.03, 40 are 0.6554 and 0.3446\n",
      "Accuracy and BER at sim_th, pop_th = 0.03, 60 are 0.6787 and 0.3213\n",
      "Accuracy and BER at sim_th, pop_th = 0.03, 80 are 0.68515 and 0.31484999999999996\n",
      "Accuracy and BER at sim_th, pop_th = 0.04, 20 are 0.57505 and 0.42495000000000005\n",
      "Accuracy and BER at sim_th, pop_th = 0.04, 40 are 0.68075 and 0.31925\n",
      "Accuracy and BER at sim_th, pop_th = 0.04, 60 are 0.70455 and 0.29545\n",
      "Accuracy and BER at sim_th, pop_th = 0.04, 80 are 0.70745 and 0.29255\n",
      "Accuracy and BER at sim_th, pop_th = 0.05, 20 are 0.576 and 0.424\n",
      "Accuracy and BER at sim_th, pop_th = 0.05, 40 are 0.6815 and 0.3185\n",
      "Accuracy and BER at sim_th, pop_th = 0.05, 60 are 0.7029 and 0.29710000000000003\n",
      "Accuracy and BER at sim_th, pop_th = 0.05, 80 are 0.70515 and 0.29485\n",
      "Accuracy and BER at sim_th, pop_th = 0.060000000000000005, 20 are 0.57625 and 0.42374999999999996\n",
      "Accuracy and BER at sim_th, pop_th = 0.060000000000000005, 40 are 0.67995 and 0.32005\n",
      "Accuracy and BER at sim_th, pop_th = 0.060000000000000005, 60 are 0.70125 and 0.29874999999999996\n",
      "Accuracy and BER at sim_th, pop_th = 0.060000000000000005, 80 are 0.70325 and 0.29675\n",
      "Accuracy and BER at sim_th, pop_th = 0.06999999999999999, 20 are 0.5758 and 0.4242\n",
      "Accuracy and BER at sim_th, pop_th = 0.06999999999999999, 40 are 0.6787 and 0.3213\n",
      "Accuracy and BER at sim_th, pop_th = 0.06999999999999999, 60 are 0.6998 and 0.3002\n",
      "Accuracy and BER at sim_th, pop_th = 0.06999999999999999, 80 are 0.7016 and 0.2984\n",
      "Accuracy and BER at sim_th, pop_th = 0.08, 20 are 0.57555 and 0.42445\n",
      "Accuracy and BER at sim_th, pop_th = 0.08, 40 are 0.678 and 0.322\n",
      "Accuracy and BER at sim_th, pop_th = 0.08, 60 are 0.69865 and 0.30135\n",
      "Accuracy and BER at sim_th, pop_th = 0.08, 80 are 0.70025 and 0.29975\n",
      "Accuracy and BER at sim_th, pop_th = 0.09, 20 are 0.5757 and 0.4243\n",
      "Accuracy and BER at sim_th, pop_th = 0.09, 40 are 0.67815 and 0.32184999999999997\n",
      "Accuracy and BER at sim_th, pop_th = 0.09, 60 are 0.69875 and 0.30125\n",
      "Accuracy and BER at sim_th, pop_th = 0.09, 80 are 0.70025 and 0.29974999999999996\n",
      "Max accuracy of 0.70745 occurs at sim, pop thresholds = 0.04, 80\n"
     ]
    }
   ],
   "source": [
    "sim_thres = [i for i in np.arange(0.01, 0.1, 0.01)]\n",
    "pop_thres = [i for i in np.arange(20,100,20)]\n",
    "accuracies = defaultdict(dict)\n",
    "max_acc, max_sim_th, max_pop_th, max_ber = -1, -1, -1, 0.5\n",
    "for sim_th in sim_thres:\n",
    "    for pop_th in pop_thres:\n",
    "        acc, BER = sim_pop(new_validation_set, sim_th, pop_th)\n",
    "        accuracies[sim_th][pop_th] = acc\n",
    "        print(\"Accuracy and BER at sim_th, pop_th = {}, {} are {} and {}\".format(sim_th, pop_th, acc, BER))\n",
    "        if(BER < max_ber):\n",
    "            max_ber = BER\n",
    "            max_acc = acc\n",
    "            max_sim_th = sim_th\n",
    "            max_pop_th = pop_th\n",
    "            \n",
    "print(\"Max accuracy of {} occurs at sim, pop thresholds = {}, {}\".\\\n",
    "      format(max_acc, max_sim_th, max_pop_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed writing!\n"
     ]
    }
   ],
   "source": [
    "test_set = []\n",
    "prediction_file = open(\"C:\\\\Users\\\\ramasarma\\\\Documents\\\\UCSD\\\\Fall 2020\\\\CSE 258\\\\Assignment1\\\\assignment1\\\\predictions_Played_hoursv2.txt\", 'w')\n",
    "for l in open(\"C:\\\\Users\\\\ramasarma\\\\Documents\\\\UCSD\\\\Fall 2020\\\\CSE 258\\\\Assignment1\\\\assignment1\\\\pairs_Played.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        prediction_file.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split('-')\n",
    "    val = {}\n",
    "    val['userID'], val['gameID'] = u, g\n",
    "    test_set.append(val)\n",
    "\n",
    "# Similarity Popularity of a given dataset\n",
    "def sim_pop(dataset, sim_th, pop_th):\n",
    "    idx, numerator = 0, 0\n",
    "    y_pred = []\n",
    "    y_act = []\n",
    "    for d in dataset:\n",
    "        u, g = d['userID'], d['gameID']\n",
    "        # Use hoursPerGame for popularity\n",
    "        # User based comparison for similarity\n",
    "        users = set(hoursPerGame_training[g])\n",
    "        max_sim = -1\n",
    "        for g2, _ in hoursPerUser_training[u]:\n",
    "            sim = jaccard(users, set(hoursPerGame_training[g2]))\n",
    "            max_sim = max(sim, max_sim)\n",
    "        # Compute the performance on validation set\n",
    "        if(max_sim > sim_th or len(hoursPerGame[g]) > pop_th):\n",
    "            prediction_file.write(u + \"-\" + g + \",1\\n\")\n",
    "        else:\n",
    "            prediction_file.write(u + \"-\" + g + \",0\\n\")\n",
    "\n",
    "sim_pop(test_set, 0.04, 80)\n",
    "print(\"Completed writing!\")\n",
    "prediction_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pop_features(dataset):\n",
    "    features = []\n",
    "    for d in dataset:\n",
    "        u, g = d['userID'], d['gameID']\n",
    "        # Use hoursPerGame for popularity\n",
    "        # User based comparison for similarity\n",
    "        users = set(hoursPerGame_training[g])\n",
    "        max_sim = -1\n",
    "        for g2, _ in hoursPerUser_training[u]:\n",
    "            sim = jaccard(users, set(hoursPerGame_training[g2]))\n",
    "            max_sim = max(sim, max_sim)\n",
    "        # Compute the performance on validation set\n",
    "        features.append([1, max_sim, len(hoursPerGame[g])])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K Fold cross validation scheme\n",
    "def kFoldCV(dataset, K):\n",
    "    random.shuffle(dataset)\n",
    "    lengthGroup = len(dataset) // K\n",
    "    idx = 0\n",
    "    train, test = defaultdict(), defaultdict()\n",
    "    \n",
    "    while(idx < K):\n",
    "        test_set = dataset[idx*lengthGroup : (idx+1) * lengthGroup]\n",
    "        if(idx == 0):\n",
    "            train_set = dataset[(idx+1) * lengthGroup:]\n",
    "        elif(idx > 1 and idx < K - 1):\n",
    "            train_set = dataset[:idx * lengthGroup] + dataset[(idx+1)*lengthGroup:]\n",
    "        elif(idx == K-1):\n",
    "            train_set = dataset[:(idx * lengthGroup)]\n",
    "        idx += 1\n",
    "        train[idx] = train_set\n",
    "        test[idx] = test_set\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]\n",
    "print(len(dataset[0]['date']))\n",
    "print(type(dataset[0]['hours_transformed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = sim_pop_features(new_training_set)\n",
    "# Y_train = [1 if i < len(new_training_set)/2 else 0 for i in range(len(new_training_set))]\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=10**-7, class_weight='balanced', max_iter = 2000)\n",
    "K = 5\n",
    "train, test = kFoldCV(new_training_set, K)\n",
    "# Here, we are building a classifier\n",
    "for i in range(K):\n",
    "    train_set = train[i+1]\n",
    "    test_set = test[i+1]\n",
    "    print(\"Lengths of train and test sets are {} and {}\".format(len(train_set), len(test_set)))\n",
    "    X_train = sim_pop_features(train_set)\n",
    "    Y_train = [1 if (len(d['date']) > 0 or d['hours_transformed'] > 0) \\\n",
    "               else 0 for d in train_set]\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Done with training for iteration \" + str(i))\n",
    "    X_val = sim_pop_features(test_set + new_validation_set)\n",
    "    Y_val_act = [1 if (len(d['date']) > 0) or (d['hours_transformed'] > 0) \\\n",
    "               else 0 for d in (test_set + new_validation_set)]\n",
    "\n",
    "    Y_val_pred = clf.predict(X_val)\n",
    "    (TP, TN, FP, FN) = compute_confusion_matrix(Y_val_act,Y_val_pred)\n",
    "    (TPR, TNR, FPR, FNR, BER) = compute_rates(TP, TN, FP, FN)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"Accuracy, BER at iteration {} are {} and {}\".format(i+1, acc, BER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sim_pop_features(new_validation_set)\n",
    "Y_test = [1 if (len(d['date']) > 0 or (d['hours_transformed'] > 0)) else 0 for d in new_validation_set]\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "(TP, TN, FP, FN) = compute_confusion_matrix(Y_test, Y_test_pred)\n",
    "(TPR, TNR, FPR, FNR, BER) = compute_rates(TP, TN, FP, FN)\n",
    "acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"Accuracy on the test set is {} and BER is {}\".format(acc, BER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6922 at lambda = 1e-08\n",
      "BER = 0.3078 at lambda = 1e-08\n",
      "Accuracy = 0.6922 at lambda = 1.2589254117941661e-08\n",
      "BER = 0.3078 at lambda = 1.2589254117941661e-08\n",
      "Accuracy = 0.69245 at lambda = 1.584893192461111e-08\n",
      "BER = 0.30755 at lambda = 1.584893192461111e-08\n",
      "Accuracy = 0.69245 at lambda = 1.9952623149688747e-08\n",
      "BER = 0.30755 at lambda = 1.9952623149688747e-08\n",
      "Accuracy = 0.69245 at lambda = 2.5118864315095718e-08\n",
      "BER = 0.30755 at lambda = 2.5118864315095718e-08\n",
      "Accuracy = 0.69265 at lambda = 3.1622776601683666e-08\n",
      "BER = 0.30735 at lambda = 3.1622776601683666e-08\n",
      "Accuracy = 0.69265 at lambda = 3.981071705534953e-08\n",
      "BER = 0.30735 at lambda = 3.981071705534953e-08\n",
      "Accuracy = 0.69265 at lambda = 5.011872336272694e-08\n",
      "BER = 0.30735 at lambda = 5.011872336272694e-08\n",
      "Accuracy = 0.69265 at lambda = 6.309573444801891e-08\n",
      "BER = 0.30735 at lambda = 6.309573444801891e-08\n",
      "Accuracy = 0.69265 at lambda = 7.943282347242757e-08\n",
      "BER = 0.30735 at lambda = 7.943282347242757e-08\n"
     ]
    }
   ],
   "source": [
    "# X_train = sim_pop_features(new_training_set)\n",
    "# X_val = sim_pop_features(new_validation_set)\n",
    "# Y_train = [1 if(len(d['date']) > 0) else 0 for d in new_training_set]\n",
    "# Y_val = [1 if len(d['date']) > 0 else 0 for d in new_validation_set]\n",
    "#model = sklearn.linear_model.LogisticRegression(C=1.0, )\n",
    "lambdas = [10 ** i for i in np.arange(-8,-7,0.1, dtype=float)]\n",
    "for lamb in lambdas:\n",
    "    model = linear_model.LogisticRegression(C=lamb, class_weight='balanced', max_iter=2000)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    #acc = sum(Y_test == validation_predictions)/len(validation_predictions)\n",
    "    (TP, TN, FP, FN) = compute_confusion_matrix(Y_val, Y_val_pred)\n",
    "    (TPR, TNR, FPR, FNR, BER) = compute_rates(TP, TN, FP, FN)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"Accuracy = {} at lambda = {}\".format(acc, lamb))\n",
    "    print(\"BER = {} at lambda = {}\".format(BER, lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_encoding(current_length, max_len):\n",
    "#     encoding = [0] * (max_len+1)\n",
    "#     assert(current_length <= max_len)\n",
    "#     encoding[current_length] = 1\n",
    "#     return encoding\n",
    "\n",
    "def sim_pop_features(dataset):\n",
    "    features = []\n",
    "    for d in dataset:\n",
    "        u, g = d['userID'], d['gameID']\n",
    "        # Use hoursPerGame for popularity\n",
    "        # User based comparison for similarity\n",
    "        users = set(hoursPerGame_training[g])\n",
    "        max_sim = -1\n",
    "        for g2, _ in hoursPerUser_training[u]:\n",
    "            sim = jaccard(users, set(hoursPerGame_training[g2]))\n",
    "            max_sim = max(sim, max_sim)\n",
    "        # Compute the performance on validation set\n",
    "        features.append([1, max_sim, len(hoursPerGame[g])])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length = 1092\n",
      "Max length = 1092\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.69 GiB for an array with shape (330000, 1095) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-00610c96a1c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mY_val_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#acc = sum(Y_test == validation_predictions)/len(validation_predictions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1345\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.69 GiB for an array with shape (330000, 1095) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train = sim_pop_features(new_training_set)\n",
    "X_val = sim_pop_features(new_validation_set)\n",
    "Y_train = [1 if(len(d['date']) > 0) else 0 for d in new_training_set]\n",
    "Y_val = [1 if len(d['date']) > 0 else 0 for d in new_validation_set]\n",
    "lambdas = [10 ** i for i in np.arange(-10,10, dtype=float)]\n",
    "\n",
    "for lamb in lambdas:\n",
    "    model = linear_model.LogisticRegression(C=lamb, class_weight='balanced', max_iter=2000)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    #acc = sum(Y_test == validation_predictions)/len(validation_predictions)\n",
    "    (TP, TN, FP, FN) = compute_confusion_matrix(Y_val, Y_val_pred)\n",
    "    (TPR, TNR, FPR, FNR, BER) = compute_rates(TP, TN, FP, FN)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"Accuracy = {} at lambda = {}\".format(acc, lamb))\n",
    "    print(\"BER = {} at lambda = {}\".format(BER, lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed writing the contents!\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(C=10**-7, class_weight='balanced', max_iter=2000)\n",
    "model.fit(X_train, Y_train)\n",
    "# Test set\n",
    "test_set = []\n",
    "prediction_file = open(\"C:\\\\Users\\\\ramasarma\\\\Documents\\\\UCSD\\\\Fall 2020\\\\CSE 258\\\\Assignment1\\\\assignment1\\\\predictions_Played.txt\", 'w')\n",
    "for l in open(\"C:\\\\Users\\\\ramasarma\\\\Documents\\\\UCSD\\\\Fall 2020\\\\CSE 258\\\\Assignment1\\\\assignment1\\\\pairs_Played.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        prediction_file.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split('-')\n",
    "    val = {}\n",
    "    val['userID'], val['gameID'] = u, g\n",
    "    test_set.append(val)\n",
    "    \n",
    "X_test = sim_pop_features(test_set)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "    u, g = test_set[i]['userID'], test_set[i]['gameID']\n",
    "    prediction_file.write(u + \"-\" + g + \",\" + str(Y_pred[i]) + \"\\n\")\n",
    "\n",
    "prediction_file.close()\n",
    "print(\"Completed writing the contents!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
